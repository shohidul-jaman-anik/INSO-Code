import Anthropic from '@anthropic-ai/sdk';
import { InMemoryChatMessageHistory } from '@langchain/core/chat_history';
import { AIMessage, HumanMessage } from '@langchain/core/messages';
import httpStatus from 'http-status';
import { BufferMemory } from 'langchain/memory';
import ApiError from '../../../errors/ApiError.js';
import { logger } from '../../../shared/logger.js';
import UserModel from '../auth/auth.model.js';
import { paymentController } from '../payment/payment.controller.js';
import Llama from './dyad.model.js';

const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
});

// In-memory session memory
const sessionMemoryStore = {};

 const claudeResponseService = async (prompt, userId, sessionId) => {
  let memory = sessionMemoryStore[sessionId];
  if (!memory) {
    memory = new BufferMemory({
      returnMessages: true,
      memoryKey: 'history',
      chatHistory: new InMemoryChatMessageHistory(),
    });
    sessionMemoryStore[sessionId] = memory;
  }

  try {
    await memory.chatHistory.addMessage(new HumanMessage(prompt));

    const previousMessages = await memory.chatHistory.getMessages();
    const messages = previousMessages.map(msg => ({
      role: msg._getType() === 'human' ? 'user' : 'assistant',
      content: msg.content,
    }));

    const startTime = Date.now();

    // Claude Sonnet 4.5 API call
    const completion = await anthropic.messages.create({
      model: 'claude-sonnet-4-5-20250929',
      max_tokens: 1500,
      messages: [...messages, { role: 'user', content: prompt }],
    });

    const endTime = Date.now();
    const totalTime = endTime - startTime;

    const reply = completion.content?.[0]?.text || 'No response generated by Claude.';

    // Payment tracking
    try {
      const paymentResult = await paymentController.incrementPromptsUsed(userId);
      if (!paymentResult.success) {
        throw new ApiError(httpStatus.BAD_REQUEST, paymentResult.message);
      }
    } catch (error) {
      logger.error('Error in incrementPromptsUsed:', error);
      throw new ApiError(
        httpStatus.INTERNAL_SERVER_ERROR,
        error.message || 'An error occurred while updating prompt usage.'
      );
    }

    await memory.chatHistory.addMessage(new AIMessage(reply));

    const responseData = {
      prompt,
      model: 'claude-sonnet-4-5-20250929',
      reply,
      total_time: totalTime,
    };

    let claudeSession = await Llama.findOne({ user: userId, sessionId });

    if (claudeSession) {
      claudeSession.responses.push(responseData);
      await claudeSession.save();
    } else {
      claudeSession = await Llama.create({
        user: userId,
        sessionId,
        responses: [responseData],
      });
      await UserModel.findByIdAndUpdate(userId, {
        $push: { llamaAiSessions: claudeSession._id },
      });
    }

    const payload = { prompt, sessionId, reply };
    console.log('Claude Response Payload:', payload);
    return payload;
  } catch (error) {
    logger.error('Error in claudeResponseService:', error);
    throw new ApiError(httpStatus.INTERNAL_SERVER_ERROR, 'Claude service failed.');
  }
};

export const ClaudeServices = {
  claudeResponseService,
};
